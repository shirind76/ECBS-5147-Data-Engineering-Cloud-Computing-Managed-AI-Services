{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2449595c",
   "metadata": {},
   "source": [
    "# Wikipedia Page Views Data Pipeline\n",
    "\n",
    "This notebook extracts the **top viewed Wikipedia pages** between 2025-11-23 and 2025-11-25, transforms the data into **JSON Lines**, and uploads it to **S3**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14484d2c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0a9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below if running this notebook locally\n",
    "# and required packages are not installed\n",
    "# %pip install requests boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3fa1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import boto3\n",
    "from datetime import datetime, timedelta, timezone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678bc40e",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Use the **same username as in the in-class Wikipedia Edits assignment**.\n",
    "\n",
    "- **Username**: `shirind76`\n",
    "- **S3 Bucket**: `shirind76-wikidata` (format: `<username>-wikidata`)\n",
    "- **Athena Database**: `shirind76` (format: `<username>`)\n",
    "- **Lambda**: Write output to the same S3 bucket (`shirind76-wikidata`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb435325",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"shirind76\"\n",
    "BUCKET = f\"{USERNAME}-wikidata\"\n",
    "\n",
    "BASE_DATE = datetime(2025, 11, 20)\n",
    "N_DAYS = 3\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0437ca6",
   "metadata": {},
   "source": [
    "### API inspection\n",
    "\n",
    "Before building the pipeline, we inspect the Wikimedia Pageviews API\n",
    "response for a single day to understand its structure.\n",
    "\n",
    "The response contains a top-level `items` array, where each element\n",
    "represents one day and includes a list of `articles` with their\n",
    "corresponding page views and rankings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f98822f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['items'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_date = BASE_DATE\n",
    "\n",
    "url = (\n",
    "    \"https://wikimedia.org/api/rest_v1/metrics/pageviews/top/\"\n",
    "    f\"en.wikipedia.org/all-access/{test_date.strftime('%Y/%m/%d')}\"\n",
    ")\n",
    "\n",
    "resp = requests.get(url, headers={\"User-Agent\": \"curl/7.68.0\"})\n",
    "resp.raise_for_status()\n",
    "\n",
    "raw = resp.json()\n",
    "\n",
    "# Professor-style inspection\n",
    "raw.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e888dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, dict_keys(['article', 'views', 'rank']))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = raw.get(\"items\", [])\n",
    "articles = items[0].get(\"articles\", []) if items else []\n",
    "len(articles), articles[0].keys() if articles else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66edcd1",
   "metadata": {},
   "source": [
    "### Extraction and transformation logic\n",
    "\n",
    "For each date, the notebook:\n",
    "1. Requests the top viewed Wikipedia pages from the Pageviews API\n",
    "2. Validates the API response\n",
    "3. Extracts article title, view count, and rank\n",
    "4. Enriches each record with the query date and a retrieval timestamp\n",
    "5. Writes the result as JSON Lines and uploads it to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb083f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_upload(date_obj):\n",
    "    date_str = date_obj.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    url = (\n",
    "        \"https://wikimedia.org/api/rest_v1/metrics/pageviews/top/\"\n",
    "        f\"en.wikipedia.org/all-access/{date_obj.strftime('%Y/%m/%d')}\"\n",
    "    )\n",
    "\n",
    "    resp = requests.get(url, headers={\"User-Agent\": \"curl/7.68.0\"})\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    retrieved_at = datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "    records = []\n",
    "    articles = data[\"items\"][0].get(\"articles\", [])\n",
    "\n",
    "    for a in articles:\n",
    "        title = a.get(\"article\")\n",
    "        views = a.get(\"views\")\n",
    "        rank = a.get(\"rank\")\n",
    "\n",
    "        if title is None or views is None or rank is None:\n",
    "            continue\n",
    "\n",
    "        records.append({\n",
    "            \"title\": title,\n",
    "            \"views\": int(views),\n",
    "            \"rank\": int(rank),\n",
    "            \"date\": date_str,\n",
    "            \"retrieved_at\": retrieved_at\n",
    "        })\n",
    "\n",
    "    key = f\"raw-views/raw-views-{date_str}.json\"\n",
    "    body = \"\\n\".join(json.dumps(r) for r in records)\n",
    "\n",
    "    s3.put_object(Bucket=BUCKET, Key=key, Body=body.encode(\"utf-8\"))\n",
    "\n",
    "    print(f\"Uploaded s3://{BUCKET}/{key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b2da81",
   "metadata": {},
   "source": [
    "### Automated multi-day extraction\n",
    "\n",
    "Instead of manually changing the date, the extraction logic is wrapped\n",
    "in a loop that automatically fetches data for multiple consecutive days\n",
    "starting from a base date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b62745f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded s3://shirind76-wikidata/raw-views/raw-views-2025-11-20.json\n",
      "Uploaded s3://shirind76-wikidata/raw-views/raw-views-2025-11-19.json\n",
      "Uploaded s3://shirind76-wikidata/raw-views/raw-views-2025-11-18.json\n"
     ]
    }
   ],
   "source": [
    "for i in range(N_DAYS):\n",
    "    fetch_and_upload(BASE_DATE - timedelta(days=i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
